{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n",
      "400000\n"
     ]
    }
   ],
   "source": [
    "embeddings_dict = {}\n",
    "words = {}\n",
    "i = 0\n",
    "glove_data = '../glove.6B.200d.txt'\n",
    "f = open(glove_data, encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    words[i] = word\n",
    "    vector = np.asarray(values[1:], \"float32\")\n",
    "    embeddings_dict[word] = vector\n",
    "    i += 1\n",
    "\n",
    "print(len(words))\n",
    "print(len(embeddings_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_embeddings_euclidean(vector_map, embedding):\n",
    "    return sorted(vector_map.keys(), key=lambda word: spatial.distance.euclidean(vector_map[word], embedding))\n",
    "\n",
    "def find_closest_embeddings_cosine(vector_map, embedding):\n",
    "    return sorted(vector_map.keys(), key=lambda word: spatial.distance.cosine(vector_map[word], embedding))\n",
    "\n",
    "def find_euclidean_distance(vec1, vec2):\n",
    "    return spatial.distance.euclidean(vec1, vec2)\n",
    "\n",
    "def find_cosine_distance(vec1, vec2):\n",
    "    return spatial.distance.cosine(vec1, vec2)\n",
    "\n",
    "def get_avg_sum_embedding(line, dictionary):\n",
    "    sum_of_vector = np.full((200, ), 0)\n",
    "    word_vec = line.split()\n",
    "    for word in word_vec:\n",
    "        embedding = dictionary.get(word, np.full((200, ), 0))\n",
    "        sum_of_vector = np.add(embedding, sum_of_vector)\n",
    "    sum_of_vector = np.divide(sum_of_vector, len(word_vec)) \n",
    "    return sum_of_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_map = 'Trane-Demos/three_datasets/flight-delay/FlightDelay.mapping'\n",
    "attr_description_map = {}\n",
    "attr_vector_map = {}\n",
    "f = open(attr_map, encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split('|')\n",
    "    word = values[0]\n",
    "    attr_description_map[word] = values[1].split('\\n')[0]\n",
    "\n",
    "for key, val in attr_description_map.items():\n",
    "    attr_vector_map[key] = get_avg_sum_embedding(val, embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict how many flights will start from this airport tomorrow\n",
      "Predict total departure delay of flights that will start from this airport tomorrow\n",
      "Predict total arrival delay of flights that will start from this airport tomorrow\n",
      "Predict total delay caused by air system of flights that will start from this airport next week\n",
      "Predict total delay caused by security of flights that will start from this airport next week\n",
      "Predict total delay caused by airline company of flights that will start from this airport for next three days\n",
      "Predict total delay caused by late aircraft of flights that will start from this airport for next three days\n",
      "Predict total delay caused by weather of flights that will start from this airport for next three days\n",
      "Predict how many flights will start from this airport tomorrow\n",
      "Predict how many flights will start with elapsed time less than five hours tomorrow\n",
      "Predict how many flights will be cancelled next week\n",
      "Predict how many flights will be cancelled because of the tornedo Mary next week\n",
      "Predict the average departure delay of all flights where air system delay is more than five minutes for next week\n",
      "Predict the average arrival delay of all flights where delay caused by weather is more than 20 minutes for tomorrow\n",
      "Predict the average scheduled duration of all flights where aircraft number is not 5 for tomorrow\n",
      "Predict the average scheduled duration of all flights where scheduled departure time is after 11:00 for tomorrow\n",
      "Predict the total arrival delay of all flights where aircraft number is 5 for tomorrow\n",
      "Predict the total airline delay of all flights where origin airport is in Newyork for tomorrow\n",
      "Predict the average airline delay of all flights where origin airport is JFK for tomorrow\n",
      "Predict the average departure delay of all flights of Quatar Airline for tomorrow\n",
      "Predict the average departure delay for each airline tomorrow\n",
      "Predict the average airline delay for each airline tomorrow\n",
      "Predict the average departure delay for each airline where elapsed time is more than five hours for tomorrow\n",
      "Predict the number of airline that will not have a flight tomorrow\n",
      "Predict the average arrival delay for each airline tomorrow\n",
      "Predict the total departure delay for each airline that will be delayed more than five minutes by air system next week\n",
      "Predict the average weather delay for each airline where id of aircraft is 5 next week\n",
      "Predict the average weather delay for each airline where departure delay is less than 5 munites for next week\n",
      "Predict the average security delay for each airline where departure delay is more than ten munites tomorrow\n",
      "Predict the average delay caused by late aircraft for each airline where elapsed time is more than seven hours for next week\n",
      "Predict all airports with cancelled flight count more than five for tomorrow\n"
     ]
    }
   ],
   "source": [
    "human_query_dict = {}\n",
    "query_file_loc = 'human_query/query.txt'\n",
    "f = open(query_file_loc, encoding=\"utf8\")\n",
    "writer = open('output.txt', 'w')\n",
    "sum_of_human_query_vector = np.full((200, ), 0)\n",
    "for line in f:\n",
    "    writer.write(line + \"\\n\")\n",
    "    query = line.split(\"|\")[0]\n",
    "    sum_of_human_query_vector = get_avg_sum_embedding(query, embeddings_dict)\n",
    "    human_query_dict[query] = sum_of_human_query_vector\n",
    "    print(query)\n",
    "    rank_euclidian = find_closest_embeddings_euclidean(attr_vector_map, sum_of_human_query_vector)\n",
    "    rank_cosine = find_closest_embeddings_cosine(attr_vector_map, sum_of_human_query_vector)\n",
    "    writer.write(\"Euclidian rank -> \" + str(rank_euclidian) + \"\\n\\n\")\n",
    "    writer.write(\"Cosine rank -> \" + str(rank_cosine) + \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
