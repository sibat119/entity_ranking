{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n",
      "400000\n"
     ]
    }
   ],
   "source": [
    "embeddings_dict = {}\n",
    "words = {}\n",
    "i = 0\n",
    "glove_data = '../glove.6B.200d.txt'\n",
    "f = open(glove_data, encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    words[i] = word\n",
    "    vector = np.asarray(values[1:], \"float32\")\n",
    "    embeddings_dict[word] = vector\n",
    "    i += 1\n",
    "\n",
    "print(len(words))\n",
    "print(len(embeddings_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_embeddings_euclidean(vector_map, embedding):\n",
    "    return sorted(vector_map.keys(), key=lambda word: spatial.distance.euclidean(vector_map[word], embedding))\n",
    "\n",
    "def find_closest_embeddings_cosine(vector_map, embedding):\n",
    "    return sorted(vector_map.keys(), key=lambda word: spatial.distance.cosine(vector_map[word], embedding))\n",
    "\n",
    "def find_euclidean_distance(vec1, vec2):\n",
    "    return spatial.distance.euclidean(vec1, vec2)\n",
    "\n",
    "def find_cosine_distance(vec1, vec2):\n",
    "    return spatial.distance.cosine(vec1, vec2)\n",
    "\n",
    "def get_avg_sum_embedding(line, dictionary):\n",
    "    sum_of_vector = np.full((200, ), 0)\n",
    "    word_vec = line.split()\n",
    "    for word in word_vec:\n",
    "        embedding = dictionary.get(word, np.full((200, ), 0))\n",
    "        sum_of_vector = np.add(embedding, sum_of_vector)\n",
    "    sum_of_vector = np.divide(sum_of_vector, len(word_vec)) \n",
    "    return sum_of_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_map = 'Trane-Demos/three_datasets/flight-delay/FlightDelay.mapping'\n",
    "attr_description_map = {}\n",
    "attr_vector_map = {}\n",
    "f = open(attr_map, encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split('|')\n",
    "    word = values[0]\n",
    "    attr_description_map[word] = values[1].split('\\n')[0]\n",
    "\n",
    "for key, val in attr_description_map.items():\n",
    "    attr_vector_map[key] = get_avg_sum_embedding(val, embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict how many flights will start from this airport tomorrow\n",
      "predict how many flights will leave the day after tomorrow\n",
      "I want to know how many flight will start monday\n",
      "Predict how many flight will depart this sunday\n",
      "Predict how many flights of Emirates Airway will be available for scheduling\n",
      "Predict how many flights of Quatar Airway will need to be rescheduled\n",
      "Predict all flight numbers with conflicting landing time because of delay\n",
      "Get all ids of flights that will depart within next week\n",
      "Get all aircraft with possible technical difficulties\n",
      "Predict how many aircraft will be delayed\n",
      "Predict all flight that will land with origin airpot Newyork\n",
      "As cyclone is coming predict which flight might land in Luisiana where they should have landed in New Maxico\n",
      "Predict number of flights with destination changed because of cyclone\n",
      "Predict number of flight leaving for Dubai next week\n",
      "Predict number of flight that will depart between 12 AM and 4 PM\n",
      "Predict flight ids whose scheduled departure time will be delayed at least one hour\n",
      "Preduict number of flight that will depart from JFK with expected flight duration of one hour\n",
      "Get number of flights with expected elapsed time less than three hours\n",
      "Get number of flights with actual elapsed time is greated than expected time tomorrow\n",
      "Predict flights which will have actual elapsed time greater than five hours within next week\n",
      "Predict number of flights with departure delay more than one hour\n",
      "Get the count of flights with no departure delay that departs tomorrow\n",
      "Predict all flights with arrival delay more than five minutes\n",
      "Predict number of flights who will have arrival delay between ten minutes to thirty minutes within next week\n",
      "Predict number of cancelled flights within next week\n",
      "Find number of cancelled flights departing from Newyork\n",
      "Predict cancelled flights within next week because of travel restriction for corona virus\n",
      "Predict number of flights entering USA will be cancelled because of terorrist attack threat\n",
      "Predict number of flights that will be delayed because of air system difficulties\n",
      "Predict flights with flight delayes more than ten minutes because of air system \n",
      "As a terorrist attack has been reported in France, predict how many flights will be delayed because of security checkup\n",
      "Predict flight delays for flights carrying refugies from Lebanon because of security delay\n",
      "Predict number of flight delays caused by airline within next week\n",
      "Get number of flights arriving to Singapore having delay caused by airline companies\n",
      "Predict number of flights that will be delayed because of shortage of aircraft\n",
      "Predict all flight delays within next week caused by the cyclone Mariya\n"
     ]
    }
   ],
   "source": [
    "human_query_dict = {}\n",
    "query_file_loc = 'human_query/query.txt'\n",
    "f = open(query_file_loc, encoding=\"utf8\")\n",
    "writer = open('output.txt', 'w')\n",
    "sum_of_human_query_vector = np.full((200, ), 0)\n",
    "for line in f:\n",
    "    writer.write(line + \"\\n\")\n",
    "    query = line.split(\"|\")[0]\n",
    "    sum_of_human_query_vector = get_avg_sum_embedding(query, embeddings_dict)\n",
    "    human_query_dict[query] = sum_of_human_query_vector\n",
    "    print(query)\n",
    "    rank_euclidian = find_closest_embeddings_euclidean(attr_vector_map, sum_of_human_query_vector)\n",
    "    rank_cosine = find_closest_embeddings_cosine(attr_vector_map, sum_of_human_query_vector)\n",
    "    writer.write(\"Euclidian rank -> \" + str(rank_euclidian) + \"\\n\\n\")\n",
    "    writer.write(\"Cosine rank -> \" + str(rank_cosine) + \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
